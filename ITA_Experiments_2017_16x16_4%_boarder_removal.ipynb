{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ITA_Experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamCorbinFAUPhD/Fairness/blob/main/ITA_Experiments_2017_16x16_4%25_boarder_removal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGtT4p7QiAht"
      },
      "source": [
        "# TESTING ISIC 2017 16x16 with 4% border removal\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZrsuKqhTO3D"
      },
      "source": [
        "# Overview\n",
        "In this colab we will go over what it takes to generate individual typology angle (ITA) values which were developed in this [paper](https://link.springer.com/chapter/10.1007/978-3-030-59725-2_31?error=cookies_not_supported&code=a61140d1-db8d-4cf8-8d67-a63e1c976380)\n",
        "\n",
        "The ITA values represent 7 different levels of skin tones\n",
        "\n",
        "|ITA Range| Skin Tone Category|Abbreviation|\n",
        "|--|--|--|\n",
        "|55$^\\circ$ $\\lt$ ITA|Very Light|very_lt|\n",
        "|48$^\\circ$ $\\lt$ ITA $\\leq$ 55$^\\circ$ |Light 2|lt2|\n",
        "|41$^\\circ$ $\\lt$ ITA $\\leq$ 48$^\\circ$|Light 1|lt1|\n",
        "|34.5$^\\circ$ $\\lt$ ITA $\\leq$ 41$^\\circ$|Intermediate 2|int2|\n",
        "|28$^\\circ$ $\\lt$ ITA $\\leq$ 34.5$^\\circ$|Intermediate 1|int1|\n",
        "|19$^\\circ$ $\\lt$ ITA $\\leq$ 28$^\\circ$|Tanned 2|tan2|\n",
        "|10$^\\circ$ $\\lt$ ITA $\\leq$ 19$^\\circ$|Tanned 1|tan1|\n",
        "|ITA $\\leq$ 10$^\\circ$|Dark|dark|\n",
        "\n",
        "The ITA uses the following equation\n",
        "\n",
        "ITA$ = archtan \\left(\\frac{L - 50}{b} \\right) \\times \\frac{180^\\circ}{\\pi}$\n",
        "\n",
        "where $L$ is luminance and $b$ is amount of yellow\n",
        "\n",
        "\n",
        "The main 3 experiments that are going to be covered here are as follows\n",
        "1. Collect the ITA values of the whole images\n",
        "2. Collect the ITA values of the cut out potion of the mask from the images\n",
        "3. Collect the ITA values of ~100 patches around the boarder of the image\n",
        "\n",
        "These results will then be compared against each other. The masked should be the ground truth since thats removing the skin lesion from the image giving a better representation for the ITA value. Then we will compare the ground truth to the 100 patches to see how well it preformed against the \"ground truth\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mBNY97TXI4k"
      },
      "source": [
        "# Setup & Get images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csa7Rt0abLLb"
      },
      "source": [
        "## Constants "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpJEYppibQuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf6c0b38-6c25-491b-bcdb-e94b540d428e"
      },
      "source": [
        "%%time\n",
        "BORDER_REMOVAL_SIZE = .04  # Going to trim %4 of the sides\n",
        "PATCH_WIDTH = 16  # Its reccomended to pick patch size that can be a multiple of 8 because of the images usually a multiple of 8\n",
        "PATCH_HEIGHT = PATCH_WIDTH\n",
        "PERCENTAGE_OF_RANDOM_PATCHES = .20\n",
        "PERCENTAGE_OF_RANDOM_PATCHES_NAME = int(PERCENTAGE_OF_RANDOM_PATCHES*100)\n",
        "TEST_RANDOM_PATCH_PERCENTAGE = False\n",
        "PERCENTAGE_OF_RANDOM_ENTROPY_SELECTED_PATCHES = .20\n",
        "PERCENTAGE_OF_RANDOM_ENTROPY_SELECTED_PATCHES_NAME = int(PERCENTAGE_OF_RANDOM_ENTROPY_SELECTED_PATCHES*100)\n",
        "\n",
        "DATASET_USED = \"ISIC_2017\" ## options ISIC_2016, ISIC_2017, ISIC_2018"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 2 µs, total: 7 µs\n",
            "Wall time: 9.78 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zpg6Ml4X3Jn"
      },
      "source": [
        "## Installs & Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUT1emEduI1M"
      },
      "source": [
        "### install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0lD2S35uH3R",
        "outputId": "5dda4a8d-3da3-41af-9126-38337f016e62"
      },
      "source": [
        "%%time\n",
        "!pip install patchify\n",
        "!pip uninstall scikit-learn -y\n",
        "!pip install -U scikit-learn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patchify\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from patchify) (1.19.5)\n",
            "Installing collected packages: patchify\n",
            "Successfully installed patchify-0.2.3\n",
            "Found existing installation: scikit-learn 0.22.2.post1\n",
            "Uninstalling scikit-learn-0.22.2.post1:\n",
            "  Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "Successfully installed scikit-learn-1.0 threadpoolctl-3.0.0\n",
            "CPU times: user 152 ms, sys: 45 ms, total: 197 ms\n",
            "Wall time: 12.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKixXJzwgSEw"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUzLzmYlYA9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a77ecb-ba40-4a70-88c2-cb1ba4c3e854"
      },
      "source": [
        "%%time\n",
        "import random\n",
        "import os\n",
        "import io\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns, matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import AutoMinorLocator\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.patches as mplpatches\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, max_error, explained_variance_score, mean_squared_log_error\n",
        "from sklearn.metrics import r2_score, mean_poisson_deviance, mean_gamma_deviance, mean_tweedie_deviance\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from skimage.filters.rank import entropy\n",
        "from skimage.morphology import disk\n",
        "from skimage.color import rgb2hsv, rgb2gray, rgb2yuv\n",
        "from skimage.io import imread\n",
        "\n",
        "from patchify import patchify\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf, re, math\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from skimage.util.shape import view_as_windows\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps\n",
        "import skimage\n",
        "import cv2\n",
        "from skimage import color\n",
        "\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "random.seed(42)\n",
        "rng = np.random.default_rng(seed=42)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.24 s, sys: 604 ms, total: 2.85 s\n",
            "Wall time: 3.69 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8jYfSymYFhJ"
      },
      "source": [
        "## Download Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5WzoD-8b42S"
      },
      "source": [
        "### ISIC 2016 Task 1 training and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clf5MX0IcFuq",
        "outputId": "0e3c3242-3f09-45d9-af96-1d659b508c52"
      },
      "source": [
        "%%time\n",
        "if DATASET_USED == \"ISIC_2016\":\n",
        "    !wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Training_Data.zip\n",
        "    !wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Test_Data.zip\n",
        "    !wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Training_GroundTruth.zip\n",
        "    !wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Test_GroundTruth.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.44 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMSC4DPVce0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eeb0ab8-721c-4374-fdbb-39ae5e5c3cf7"
      },
      "source": [
        "%%time\n",
        "if DATASET_USED == \"ISIC_2016\":\n",
        "    !unzip ISBI2016_ISIC_Part1_Training_Data.zip -d ISIC_2016 > /dev/null.\n",
        "    !unzip ISBI2016_ISIC_Part1_Test_Data.zip -d ISIC_2016 > /dev/null.\n",
        "    !unzip ISBI2016_ISIC_Part1_Training_GroundTruth.zip -d ISIC_2016_GT > /dev/null.\n",
        "    !unzip ISBI2016_ISIC_Part1_Test_GroundTruth.zip -d ISIC_2016_GT > /dev/null."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
            "Wall time: 6.2 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9g79VLTc_3j",
        "outputId": "4398e8ff-8241-41d0-c4bc-6fbfb5a7e1ae"
      },
      "source": [
        "%%time\n",
        "if DATASET_USED == \"ISIC_2016\":\n",
        "    # Display both 1 mask and 1 regular file\n",
        "    index = 0\n",
        "    files = Path(\"ISIC_2016\").glob(\"**/*.jpg\")\n",
        "    org = \"\"\n",
        "    org_files = []\n",
        "    for file in files:\n",
        "        org_files.append(file)\n",
        "        \n",
        "    org_files.sort()\n",
        "    print(org_files[index])\n",
        "    org = Image.open(org_files[index])\n",
        "        \n",
        "    gt_files = Path(\"ISIC_2016_GT\").glob(\"**/*.png\")\n",
        "    gt = \"\"\n",
        "    gt_files_list = []\n",
        "    for file in gt_files:\n",
        "        gt_files_list.append(file)\n",
        "        \n",
        "    gt_files_list.sort()    \n",
        "    print(gt_files_list[index])\n",
        "    gt = Image.open(gt_files_list[index])\n",
        "\n",
        "    ax = plt.subplot(1, 2, 1)\n",
        "\n",
        "    plt.imshow(org,aspect=.7)\n",
        "    plt.title(\"Original Iamge\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.subplots_adjust(hspace = .5)\n",
        "\n",
        "    ax = plt.subplot(1, 2,2)\n",
        "\n",
        "    plt.imshow(gt,aspect=.7)\n",
        "    plt.title(\"Masked Image\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.subplots_adjust(hspace = .5)\n",
        "\n",
        "    print(f\"Same size? {len(org_files) == len(gt_files_list)} {len(org_files)}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
            "Wall time: 11 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_nWuUWtb_3m"
      },
      "source": [
        "### ISIC 2017 dataset\n",
        "This includes the training, validation, and test data resised to 192 x 256. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8_VncvZJV5B",
        "outputId": "93d57f64-0c1a-4728-d167-6439d19bc26e"
      },
      "source": [
        "%%time\n",
        "if DATASET_USED == \"ISIC_2017\":\n",
        "    !git clone https://github.com/manideep2510/melanoma_segmentation.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'melanoma_segmentation'...\n",
            "remote: Enumerating objects: 5578, done.\u001b[K\n",
            "remote: Total 5578 (delta 0), reused 0 (delta 0), pack-reused 5578\u001b[K\n",
            "Receiving objects: 100% (5578/5578), 101.46 MiB | 24.61 MiB/s, done.\n",
            "Resolving deltas: 100% (464/464), done.\n",
            "Checking out files: 100% (5509/5509), done.\n",
            "CPU times: user 72.4 ms, sys: 21.6 ms, total: 94 ms\n",
            "Wall time: 7.36 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1syKTgFksZu"
      },
      "source": [
        "### ISIC 2018\n",
        "https://challenge.isic-archive.com/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80Pt74EGmSve",
        "outputId": "8d17b139-207e-446a-bd75-7ebfcd9f9f80"
      },
      "source": [
        "%%time\n",
        "if DATASET_USED == \"ISIC_2018\":\n",
        "    !wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Training_Input.zip\n",
        "    !wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1_Training_GroundTruth.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 6.2 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uVFQJplmdLt",
        "outputId": "66354c41-a04a-44fa-e32d-cf9abf0afcf6"
      },
      "source": [
        "%%time\n",
        "if DATASET_USED == \"ISIC_2018\":\n",
        "    !unzip ISIC2018_Task1-2_Training_Input.zip -d ISIC_2018 > /dev/null.\n",
        "    !unzip ISIC2018_Task1_Training_GroundTruth.zip -d ISIC_2018_GT > /dev/null."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 6.68 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GstydAP5Yd00"
      },
      "source": [
        "# Organize images into a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "semQLFDyghXQ"
      },
      "source": [
        "## Read all image paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skELabM2Y1uC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41306224-8b87-4b50-a053-228277943724"
      },
      "source": [
        "%%time\n",
        "\"\"\"\n",
        "This section we read all the images including their masks. \n",
        "\"\"\"\n",
        "\n",
        "orig_images = []\n",
        "masks_images = []\n",
        "\n",
        "if DATASET_USED == \"ISIC_2016\":\n",
        "    for file in Path(\"ISIC_2016\").glob(\"**/*.jpg\"):        \n",
        "        orig_images.append(file)\n",
        "\n",
        "    for file in Path(\"ISIC_2016_GT\").glob(\"**/*.png\"):\n",
        "        masks_images.append(file)\n",
        "\n",
        "if DATASET_USED == \"ISIC_2017\":\n",
        "    \"\"\" Since we are just using this to test the ITA values we can join \n",
        "        the test, train and validation sets\n",
        "    \"\"\"\n",
        "    folders_to_search = [\"test\",\"train\",\"validation\"]\n",
        "    for folder in folders_to_search:\n",
        "        for file in Path(f\"melanoma_segmentation/{folder}x\").glob(\"*.jpg\"):        \n",
        "            orig_images.append(file)\n",
        "\n",
        "        for file in Path(f\"melanoma_segmentation/{folder}y\").glob(\"*.jpg\"):\n",
        "            masks_images.append(file)\n",
        "\n",
        "if DATASET_USED == \"ISIC_2018\":\n",
        "    for file in Path(\"ISIC_2018\").glob(\"**/*.jpg\"):        \n",
        "        orig_images.append(file)\n",
        "\n",
        "    for file in Path(\"ISIC_2018_GT\").glob(\"**/*.png\"):\n",
        "        masks_images.append(file)\n",
        "\n",
        "print(len(orig_images))\n",
        "print(len(masks_images))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2750\n",
            "2750\n",
            "CPU times: user 150 ms, sys: 14.5 ms, total: 165 ms\n",
            "Wall time: 163 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HNgn1EUUAge"
      },
      "source": [
        "def strip_filename(file):\n",
        "    \"\"\"\n",
        "    This function makes an identifier that matches between both the base image and the masked image\n",
        "    \"\"\"\n",
        "    if DATASET_USED == \"ISIC_2017\":\n",
        "        # Cleaning files names here: https://github.com/manideep2510/melanoma_segmentation.git\n",
        "        fn = file.name.replace(\"imgx\",\"\")\n",
        "        fn = fn.replace(\"imgy\",\"\")\n",
        "        path = file.parent.parts[-1].replace(\"x\",\"\").replace(\"y\",\"\")\n",
        "\n",
        "    # Cleaning ISIC 2016 filenames\n",
        "    if DATASET_USED == \"ISIC_2016\":\n",
        "        fn = file.name.replace(\"_Segmentation\",\"\").replace(\".jpg\",\"\").replace(\".png\",\"\")\n",
        "        path = file.parent.parts[-1].replace(\"_Data\",\"\").replace(\"_GroundTruth\",\"\")\n",
        "    \n",
        "    uuid = f\"{path}/{fn}\"\n",
        "    return uuid"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K1LtIdLluZx"
      },
      "source": [
        "def create_masked_image(image, mask):\n",
        "    \"\"\"\n",
        "    This function takes in an image and mask in bytes. Since the mask is intended to be used to selecte the\n",
        "    skin leison we need to invert the mask so we can remove the skin leison. Once invert, the mask is applied the\n",
        "    origional image and then the new masked_image is return as a byte array.\n",
        "    \"\"\"\n",
        "    \n",
        "    orig_image = Image.open(io.BytesIO(image))\n",
        "    \n",
        "    imgpx = np.array(orig_image)\n",
        "\n",
        "    mask_bytes = io.BytesIO(mask)\n",
        "    mask = Image.open(mask_bytes)\n",
        "    mask = ImageOps.invert(mask) # need to invert the mask because we want to only remove the skin lesion \n",
        "    mask_pix = np.array(mask)    \n",
        "\n",
        "    # Adding the mask to the image \n",
        "    image_masked = np.where(mask_pix[...,None], imgpx,0)\n",
        "    im_byte_array = Image.fromarray(image_masked)\n",
        "\n",
        "    # Saving the masked image to a byte array\n",
        "    img_byte_arr = io.BytesIO()\n",
        "    orig_image = im_byte_array.convert('RGB')\n",
        "    orig_image.save(img_byte_arr, format=\"JPEG\")\n",
        "    img_byte_arr = img_byte_arr.getvalue()\n",
        "    return img_byte_arr"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glzx5vnhhDlU"
      },
      "source": [
        "## Create dataframe with images and masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XxESythkC_s"
      },
      "source": [
        "%%time\n",
        "dict_data = {}\n",
        "data_list = []\n",
        "for file in orig_images:    \n",
        "    dict_data[strip_filename(file)] = file\n",
        "\n",
        "for file in masks_images:\n",
        "    \n",
        "    # Adding the previous image to the new item so it will include both mask and iamge    \n",
        "    image = open(dict_data[strip_filename(file)],\"rb\").read()    \n",
        "    mask = open(file,\"rb\").read()\n",
        "\n",
        "    # now to cut the mask out of the image\n",
        "    masked_image = create_masked_image(image, mask)\n",
        "    data_list.append([strip_filename(file), image, mask, masked_image ])\n",
        "    \n",
        "\n",
        "# now to create the dataframe\n",
        "df = pd.DataFrame(data=data_list, columns=[\"ID\",\"image\", \"mask\", \"masked_image\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isx_R1wrYOu7"
      },
      "source": [
        "### Compute the masked percentage of the whole image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY-F07s-ZwRP"
      },
      "source": [
        "def compute_mask_percentage(row):\n",
        "    mask_array = np.array(Image.open(io.BytesIO(row[\"mask\"])))    \n",
        "    total = mask_array.size\n",
        "    mask_count = np.count_nonzero(mask_array)\n",
        "\n",
        "    percentage = mask_count / total\n",
        "    row[\"mask_percentage\"] = math.ceil(percentage * 100)\n",
        "    return row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwnsEfdDaUK-"
      },
      "source": [
        "%%time\n",
        "df = df.apply(compute_mask_percentage, axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AANJ51az3jpK"
      },
      "source": [
        "### Display dataframe item and images\n",
        "\n",
        "Sample just 1 image to display the origional and origional with the masked leasion removed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DdwKM7onvbp"
      },
      "source": [
        "%%time\n",
        "index = 0\n",
        "item = df.iloc[index] \n",
        "print(item)\n",
        "mask = item[\"mask\"]\n",
        "image = item[\"image\"]\n",
        "img = io.BytesIO(mask)\n",
        "mask = Image.open(img)\n",
        "mask = ImageOps.invert(mask) # need to invert the mask because we want to only remove the skin lesion \n",
        "\n",
        "orig_image = Image.open(io.BytesIO(image))\n",
        "pix = np.array(mask)\n",
        "imgpx = np.array(orig_image)\n",
        "image_masked = np.where(pix[...,None], imgpx,0)\n",
        "print(\"Shape of image: \", imgpx.shape)\n",
        "\n",
        "im = Image.fromarray(image_masked)\n",
        "\n",
        "\n",
        "ax = plt.subplot(1, 2, 1)\n",
        "image = Image.open(io.BytesIO(item[\"image\"]))\n",
        "plt.imshow(image,aspect=.7)\n",
        "plt.title(\"Original Iamge\")\n",
        "plt.axis(\"off\")\n",
        "plt.subplots_adjust(hspace = .5)\n",
        "\n",
        "ax = plt.subplot(1, 2,2)\n",
        "image = Image.open(io.BytesIO(item[\"masked_image\"]))\n",
        "plt.imshow(image,aspect=.7)\n",
        "plt.title(\"Masked Image\")\n",
        "plt.axis(\"off\")\n",
        "plt.subplots_adjust(hspace = .5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbtUbJyyq_cV"
      },
      "source": [
        "# ITA experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4Gy7nRHzH5z"
      },
      "source": [
        "#### Compute border removal amount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujc0Hb5cyJlw"
      },
      "source": [
        "def get_border_removal_size(image):\n",
        "    \"\"\"\n",
        "    This function will compute the border removal size based on the width of the image as well as depending on the patch\n",
        "    size to insure that the patches will covert the full image\n",
        "    \"\"\"\n",
        "    w, h = image.size\n",
        "    return int(math.ceil(w * BORDER_REMOVAL_SIZE / PATCH_WIDTH)) * PATCH_WIDTH\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nXfMb5K3w9M"
      },
      "source": [
        "def trim_boarder_from_image(pil_image):\n",
        "    w, h = pil_image.size\n",
        "    removal_size = get_border_removal_size(pil_image)\n",
        "    cropped_area = (removal_size,removal_size,w - removal_size, h - removal_size)\n",
        "    cropped_image = pil_image.crop(cropped_area)\n",
        "    return cropped_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRqcpK6ShJja"
      },
      "source": [
        "## Compute the ITA value for each image\n",
        "\n",
        "This section is a simple ITA computation on the images that are masked and unmasked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx9OgOd7rp1i"
      },
      "source": [
        "def compute_ita_from_lab(lab):\n",
        "    # get the luminance and b values wihtin +- 1 std from mean\n",
        "    l = lab[:,:,0]\n",
        "    l = np.where(l != 0, l, np.nan)\n",
        "    std = np.nanstd(l)\n",
        "    mean = np.nanmean(l)\n",
        "    \n",
        "    l = np.where(l >= mean - std, l, np.nan)\n",
        "    l = np.where(l <= mean + std, l, np.nan)\n",
        "        \n",
        "    b = lab[:,:,2]\n",
        "    std = np.nanstd(b)\n",
        "    mean = np.nanmean(b)\n",
        "    b = np.where(b >= mean - std, b, np.nan)\n",
        "    b = np.where(b <= mean + std, b, np.nan)\n",
        "\n",
        "\n",
        "    ita = math.atan2(np.nanmean(l) - 50, np.nanmean(b)) * (180 / np.pi)\n",
        "    return ita"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S62KD4focl2p"
      },
      "source": [
        "def compute_ita(image, crop_border=False):\n",
        "    img = io.BytesIO(image)\n",
        "    pilimae = Image.open(img)  \n",
        "\n",
        "    if crop_border:\n",
        "        w, h = pilimae.size\n",
        "        removal_size = get_border_removal_size(pilimae)\n",
        "        cropped_area = (removal_size,removal_size,w - removal_size, h - removal_size)\n",
        "        pilimae = pilimae.crop(cropped_area)      \n",
        "\n",
        "    \n",
        "    lab = np.array(skimage.color.rgb2lab(pilimae))\n",
        "    return compute_ita_from_lab(lab)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC9IcxwRhhDt"
      },
      "source": [
        "%%time\n",
        "df[\"ITA_orig\"] = df[\"image\"].apply(compute_ita,crop_border=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Brs748TpoV-k"
      },
      "source": [
        "%%time\n",
        "df[\"ITA_masked\"] = df[\"masked_image\"].apply(compute_ita,crop_border=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cordk5PbNMA-"
      },
      "source": [
        "##Patches experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXzaas1zL_M9"
      },
      "source": [
        " ### Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zVO77fb2cpX"
      },
      "source": [
        "#### Creating patches from an image\n",
        "Later on there will be processing to select the individual patches based on the tecnique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gVTP7Bw4hzq"
      },
      "source": [
        "def format_image_and_get_patches(image):\n",
        "    img = io.BytesIO(image)\n",
        "    pil_image = Image.open(img) \n",
        "\n",
        "    # Crop image to remove the pixels from the boarder\n",
        "    w, h = pil_image.size\n",
        "    removal_size = get_border_removal_size(pil_image)\n",
        "    cropped_area = (removal_size,removal_size,w - removal_size, h - removal_size)\n",
        "    cropped_image = pil_image.crop(cropped_area)\n",
        "\n",
        "\n",
        "    #print(\"pil_image\", np.array(pil_image).shape)\n",
        "    #print(\"cropped_image\", np.array(cropped_image).shape)\n",
        "    # Convert image to lab values\n",
        "    lab = np.array(skimage.color.rgb2lab(cropped_image))\n",
        "\n",
        "    # Get the patches\n",
        "    return patchify(lab, (PATCH_WIDTH,PATCH_HEIGHT,3), step=PATCH_WIDTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_17LLPX2t3X"
      },
      "source": [
        "#### Display 1 image with the selected patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTgr0DF72_MX"
      },
      "source": [
        "def display_single_image_and_selected_patches(image_in_bytes, selected_coords):\n",
        "    img = io.BytesIO(image_in_bytes)\n",
        "\n",
        "    im = Image.open(img)\n",
        "\n",
        "    # Create figure and axes\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Display the image\n",
        "    ax.imshow(im)\n",
        "\n",
        "    removal_size = get_border_removal_size(im)\n",
        "    print(\"removal size\", removal_size)\n",
        "\n",
        "    for coord in selected_coords:\n",
        "        # Create a Rectangle patch    \n",
        "        x = coord[0] * PATCH_WIDTH + removal_size\n",
        "        y = int(coord[1] * PATCH_WIDTH) + removal_size    \n",
        "        rect = mplpatches.Rectangle((y, x), PATCH_HEIGHT, PATCH_WIDTH, linewidth=1, edgecolor='b', facecolor='none')\n",
        "\n",
        "        # Add the patch to the Axes\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-5PS0pONd-B"
      },
      "source": [
        "### ITA on all patches\n",
        "This section will get the ITA value for all patches within a given image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWozVMai4SMp"
      },
      "source": [
        "def get_ita_for_all_patches(image):\n",
        "    patches = format_image_and_get_patches(image)\n",
        "    # Capture all the ITA values for each patch. \n",
        "    ita_values = []\n",
        "    indices = []\n",
        "    for x, x_item in enumerate(patches):\n",
        "        for y, y_item in enumerate(patches[x]):        \n",
        "            patch = patches[x][y][0]        \n",
        "            ita_values.append(compute_ita_from_lab(patch))  \n",
        "            indices.append([x,y])\n",
        "    return ita_values, indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI_OVQfN7Ovr"
      },
      "source": [
        "#### Test 1 image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-FUSZU77Q07"
      },
      "source": [
        "%%time\n",
        "full_image_ita, full_image_coords = get_ita_for_all_patches(df.iloc[0][\"image\"])\n",
        "display_single_image_and_selected_patches(df.iloc[0][\"image\"],full_image_coords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG1vK1NOLLPx"
      },
      "source": [
        "### Cropped center"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwDLyocDCxYM"
      },
      "source": [
        "def get_cropped_center_patches_ita_list(image, verbose=False):\n",
        "    \"\"\"\n",
        "    For the structure patches approach the first row, the last row, first column and last column will be \n",
        "    sampled for the ITA values.\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    Note we want to ignore the center part of the images. We will take 15% around the center of the image and ignore getting the ITA\n",
        "    values for those images. Taking 15% of the width and height will get offset value. Then dividing the width and height by 2\n",
        "    will be the mid-point which we can take the offset and do a +- to get a range where we dont want to capture the ITA values\n",
        "    as long as the x and y indexes dont fall between both ranges then we will capture the ITA values of the image.\n",
        "\n",
        "    \"\"\"\n",
        "    patches = format_image_and_get_patches(image)\n",
        "\n",
        "    center_removal_percentage = .70/2\n",
        "    h = len(patches)\n",
        "    w = len(patches[0])\n",
        "\n",
        "    w_offset = math.floor(w * center_removal_percentage)\n",
        "    h_offset = math.floor(h * center_removal_percentage)\n",
        "\n",
        "    w_mid = int(w/2)\n",
        "    h_mid = int(h/2)\n",
        "\n",
        "    indices = []\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Will ignore values in these ranges\")\n",
        "        print(\"center_removal_percentage\",center_removal_percentage)\n",
        "        print(\"w\",w)\n",
        "        print(\"h\",h)\n",
        "        print(\"w_offset\",w_offset)\n",
        "        print(\"h_offset\",h_offset)\n",
        "        print(\"w_mid\",w_mid)\n",
        "        print(\"h_mid\",h_mid)\n",
        "        w_range = (w_mid + w_offset) - (w_mid - w_offset)\n",
        "        print(f\"w range diff {w_range} : % {w_range/w}\")\n",
        "        h_range = (h_mid + h_offset) - (h_mid - h_offset)\n",
        "        print(f\"h range diff {h_range} : %{h_range/h}\")\n",
        "        print(f\"{w_mid - w_offset} <= x < {w_mid + w_offset} and {h_mid - h_offset} <= y < {h_mid + h_offset}\")\n",
        "    selected_ita_values = []\n",
        "    for y, y_item in enumerate(patches):\n",
        "        for x, x_item in enumerate(patches[y]):\n",
        "            if w_mid - w_offset <= x < w_mid + w_offset and h_mid - h_offset <= y < h_mid + h_offset:\n",
        "                continue\n",
        "            patch = patches[y][x][0]        \n",
        "            selected_ita_values.append(compute_ita_from_lab(patch)) \n",
        "            indices.append([y,x])\n",
        "    \n",
        "    return selected_ita_values, indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgyNFuFTLCbh"
      },
      "source": [
        "def get_cropped_center_ita(row):\n",
        "    image = row[\"image\"]\n",
        "    ita_values, indices = get_cropped_center_patches_ita_list(image)\n",
        "    row[\"ITA_center_cropped_all\"] = ita_values\n",
        "    row[\"ITA_center_cropped\"] = np.median(ita_values)\n",
        "    row[\"ITA_center_cropped_indices\"] = indices\n",
        "    return row "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrpjG0sx6tY-"
      },
      "source": [
        "#### Test 1 image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izilgaUd6v6X"
      },
      "source": [
        "%%time\n",
        "ita, cropped_center_coords = get_cropped_center_patches_ita_list(df.iloc[0][\"image\"], verbose=True)\n",
        "print(cropped_center_coords)\n",
        "display_single_image_and_selected_patches(df.iloc[0][\"image\"],cropped_center_coords)\n",
        "print(len(cropped_center_coords), len(full_image_coords), len(cropped_center_coords)/ len(full_image_coords))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUahsoU1svkS"
      },
      "source": [
        "### Structured Patches\n",
        "\n",
        "Creating masks can be difficult to obtain from either working with medical professionals to generate the masks or even developing an AI segmentation solution to generate the masks. In this alternate approach the idea would be to take small patches around the boarder of the image. The center of the image will not be sampled as we are assuming that skin lesion will be around that potion of the image. Also the absolute boarder will be also ignored with an assumption that there might be some bad artifacts around the boarder that would not represent the skin tones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbzzTeenFpLg"
      },
      "source": [
        "def get_structured_patches_ita_list(image):\n",
        "    \"\"\"\n",
        "    For the structure patches approach the first row, the last row, first column and last column will be \n",
        "    sampled for the ITA values. When taking the boarder we need ot make sure the corners are not double counted\n",
        "    \"\"\"\n",
        "    patches = format_image_and_get_patches(image)\n",
        "\n",
        "    selected_ita_values = []\n",
        "\n",
        "    row_count = len(patches)\n",
        "    col_count = len(patches[0])\n",
        "    \n",
        "\n",
        "    indices = []\n",
        "    # First row\n",
        "    for i, patch in enumerate(patches[0]):        \n",
        "        selected_ita_values.append(compute_ita_from_lab(patch[0])) \n",
        "        indices.append([0,i])\n",
        "    # last row\n",
        "    for i, patch in enumerate(patches[-1]):        \n",
        "        selected_ita_values.append(compute_ita_from_lab(patch[0])) \n",
        "        indices.append([row_count - 1,i])\n",
        "    # First column\n",
        "    # Not index zero and last index is a corner and already accounted for on the rows\n",
        "    for i in range(1,row_count - 1):\n",
        "        patch = patches[i][0]\n",
        "        selected_ita_values.append(compute_ita_from_lab(patch[0])) \n",
        "        indices.append([i,0])\n",
        "\n",
        "    # Last column\n",
        "    # Not index zero and last index is a corner and already accounted for on the rows\n",
        "    for i in range(1,row_count - 1):\n",
        "        patch = patches[i][-1]\n",
        "        selected_ita_values.append(compute_ita_from_lab(patch[0]))\n",
        "        indices.append([i,col_count-1])\n",
        "\n",
        "\n",
        "    return selected_ita_values, indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCkSKAgi35fA"
      },
      "source": [
        "def get_structured_patches_ita(row):\n",
        "    \"\"\"\n",
        "    This function is intended to add the ITA represented value dataframe for an instance. \n",
        "    Its intended to be used with the df.apply() method\n",
        "    \"\"\"\n",
        "    image = row[\"image\"]\n",
        "    ita_values, indices = get_structured_patches_ita_list(image)\n",
        "    row[\"ITA_structured_patches_all\"] = ita_values\n",
        "    row[\"ITA_structured_patches\"] = np.median(ita_values)\n",
        "    row[\"ITA_structured_patches_indices\"] = indices\n",
        "\n",
        "    return row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOy5RywwvqU4"
      },
      "source": [
        "#### Testing 1 image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQMVmWwarGNw"
      },
      "source": [
        "%%time\n",
        "ita, coords = get_structured_patches_ita_list(df.iloc[0][\"image\"])\n",
        "display_single_image_and_selected_patches(df.iloc[0][\"image\"],coords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxeCO_qgMSGs"
      },
      "source": [
        "### Random patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yLYDxo9Yu9Y"
      },
      "source": [
        "# randomly pick numbers between 0 and max patches\n",
        "def get_random_patches_ita_list(image,percentage=PERCENTAGE_OF_RANDOM_PATCHES, verbose=False):\n",
        "    \"\"\"\n",
        "    The premise behind random patches is that a set of patches that do not overlap a generated and at random patches \n",
        "    be sampled to take the ITA value from. The thought would be that because its a random sample that the majority should\n",
        "    cover or represent the skin tone. It is possible that some of the patches could cover a skin lesion which will be address in \n",
        "    a future approach.\n",
        "    \"\"\"\n",
        "    patches = format_image_and_get_patches(image)\n",
        "    row_count = len(patches)\n",
        "    column_count = len(patches[0])\n",
        "    \n",
        "    patch_count = row_count * column_count\n",
        "    \n",
        "    random_to_select = int(patch_count * percentage)\n",
        "    \n",
        "    # Generate a random list of numbers with no duplicates\n",
        "    random_patch_indexes = rng.choice(patch_count, size=random_to_select, replace=False)\n",
        "    random_patch_indexes.sort()\n",
        "    \n",
        "    # get reverse indexes. The index number comes from nRow * col_count + nCol. \n",
        "    # so for example if you have 10x10 image. image index 23 is row 2 col 4. The formula would be 2*10 + 4 = 24\n",
        "    # x = number % column_count\n",
        "    # y = int(number / column_count) \n",
        "    \n",
        "    coordinate_indices = []\n",
        "    for index in random_patch_indexes:\n",
        "        y = index % column_count\n",
        "        x = int(index /column_count)\n",
        "        coordinate_indices.append([x,y])\n",
        "    if verbose:\n",
        "        print(f\"row_count {row_count} column_count {column_count} \")\n",
        "        print(f\"patch_count {patch_count}, random_to_select {random_to_select}\")\n",
        "        print(f\"random_patch_indexes\\n{random_patch_indexes}\")\n",
        "        print(f\"coordinate_indices\\n{coordinate_indices}\")\n",
        "\n",
        "    ita_values = []\n",
        "    for index in coordinate_indices:\n",
        "        x = index[1]\n",
        "        y = index[0]\n",
        "        patch = patches[y][x]\n",
        "        ita_values.append(compute_ita_from_lab(patch[0]))\n",
        "    return ita_values, coordinate_indices\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoESB4CclIsm"
      },
      "source": [
        "def get_random_patches_ita(row,percentage=PERCENTAGE_OF_RANDOM_PATCHES):\n",
        "    \"\"\"\n",
        "    This function is intended to add the ITA represented value dataframe for an instance. \n",
        "    Its intended to be used with the df.apply() method\n",
        "    \"\"\"\n",
        "\n",
        "    image = row[\"image\"]\n",
        "    \n",
        "    ita_values, indices = get_random_patches_ita_list(image, percentage)\n",
        "    row[f\"ITA_random_patches_{int(percentage*100)}_all\"] = ita_values\n",
        "    row[f\"ITA_random_patches_{int(percentage*100)}\"] = np.median(ita_values)\n",
        "    row[f\"ITA_random_patches_{int(percentage*100)}_indices\"] = indices\n",
        "    return row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CphaxrHMvfT7"
      },
      "source": [
        "#### Testing 1 image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V5ABg0-lXlJ"
      },
      "source": [
        "%%time\n",
        "ita, coords = get_random_patches_ita_list(df.iloc[0][\"image\"],verbose=True)\n",
        "display_single_image_and_selected_patches(df.iloc[0][\"image\"],coords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCcqZia55_8Q"
      },
      "source": [
        "#### Showing Random 100%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRDxiC305fMe"
      },
      "source": [
        "%%time\n",
        "ita_random_100, coords_random_100 = get_random_patches_ita_list(df.iloc[0][\"image\"],percentage=1,verbose=True)\n",
        "display_single_image_and_selected_patches(df.iloc[0][\"image\"],coords_random_100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ox-0Nrb6Mdq"
      },
      "source": [
        "#### Compare Random 100% vs all patches \n",
        "Test using the rMSE and MAE between both the full image and random 100%. If they were any different there would have a value greater than 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WCKGSR86Ljr"
      },
      "source": [
        "rmse = mean_squared_error(full_image_ita, ita_random_100, squared=False)\n",
        "mae = mean_absolute_error(full_image_ita, ita_random_100)\n",
        "print(\"rmse\",rmse)\n",
        "print(\"mae\",mae)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6FLdJUBiQyK"
      },
      "source": [
        "%%time\n",
        "# display image, \n",
        "# add rectangles on each of the patches\n",
        "\n",
        "img = io.BytesIO(df.iloc[0][\"image\"])\n",
        "\n",
        "im = Image.open(img)\n",
        "\n",
        "# Create figure and axes\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Display the image\n",
        "ax.imshow(im)\n",
        "removal_size = get_border_removal_size(im)\n",
        "for coord in coords:\n",
        "    # Create a Rectangle patch    \n",
        "    x = coord[0] * PATCH_WIDTH + removal_size\n",
        "    y = int(coord[1] * PATCH_WIDTH) + removal_size\n",
        "    rect = mplpatches.Rectangle((y, x), PATCH_HEIGHT, PATCH_WIDTH, linewidth=1, edgecolor='b', facecolor='none')\n",
        "\n",
        "    # Add the patch to the Axes\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgI3sCShStoU"
      },
      "source": [
        "#### Test Random Patch percentage\n",
        "The idea here is to check and see if different percentages work better than others. Starting from 5 percent to 100%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfidMUdUS4BU"
      },
      "source": [
        "%%time\n",
        "if TEST_RANDOM_PATCH_PERCENTAGE:\n",
        "    df_percent  = pd.DataFrame()\n",
        "    columns_to_test = [\"ITA_orig\"]\n",
        "    results = []\n",
        "    for percent in range(5,101,5):\n",
        "        col = f\"ITA_random_patches_{percent}\"\n",
        "        columns_to_test.append(col)\n",
        "        # df_percent[f\"percent_{percent}\"]\n",
        "        df_percent = df.apply(get_random_patches_ita, percentage=percent/100,axis=1)\n",
        "        res = f\"{col} {compute_metrics(df_percent,col)}\"\n",
        "        results.append(res)\n",
        "        print(res)\n",
        "    \n",
        "    for res in results:\n",
        "        print(results)\n",
        "        \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln0jnXL4z4qw"
      },
      "source": [
        "%%time\n",
        "if TEST_RANDOM_PATCH_PERCENTAGE:\n",
        "    #results = [\"ITA_random_patches_5 {'Root Mean Squared Error': 22.644068119396845, 'Mean Absolute Error': 9.433725404146573, 'Max error': 295.34283795198667, 'Mean Squared Error': 512.7538209958846, 'Explained Variance Score': 0.5116493813766296, 'R^2 Score': 0.4665957747335927}\", \"ITA_random_patches_10 {'Root Mean Squared Error': 21.517008523395074, 'Mean Absolute Error': 8.947842487466325, 'Max error': 158.57299716134094, 'Mean Squared Error': 462.9816557958562, 'Explained Variance Score': 0.5665311433693841, 'R^2 Score': 0.5182531908526522}\", \"ITA_random_patches_15 {'Root Mean Squared Error': 21.506358967855427, 'Mean Absolute Error': 8.846049598928758, 'Max error': 202.0117662354209, 'Mean Squared Error': 462.5234760542555, 'Explained Variance Score': 0.5653247491299809, 'R^2 Score': 0.5185923546519003}\", \"ITA_random_patches_20 {'Root Mean Squared Error': 21.853179995033013, 'Mean Absolute Error': 8.857193037321805, 'Max error': 266.78169215557216, 'Mean Squared Error': 477.56147589531105, 'Explained Variance Score': 0.547916929490478, 'R^2 Score': 0.5029403748735195}\", \"ITA_random_patches_25 {'Root Mean Squared Error': 21.740403670052697, 'Mean Absolute Error': 8.74870893140257, 'Max error': 274.26924368171564, 'Mean Squared Error': 472.6451517368408, 'Explained Variance Score': 0.5482075182651247, 'R^2 Score': 0.5031824540447969}\", \"ITA_random_patches_30 {'Root Mean Squared Error': 21.940985036962108, 'Mean Absolute Error': 8.77365406080374, 'Max error': 274.7889267498498, 'Mean Squared Error': 481.40682439219506, 'Explained Variance Score': 0.5423855532015973, 'R^2 Score': 0.499061289223536}\", \"ITA_random_patches_35 {'Root Mean Squared Error': 21.977407915876498, 'Mean Absolute Error': 8.803526885764086, 'Max error': 272.2413843180926, 'Mean Squared Error': 483.00645870083093, 'Explained Variance Score': 0.5409097793099651, 'R^2 Score': 0.497396753725325}\", \"ITA_random_patches_40 {'Root Mean Squared Error': 21.71747887437951, 'Mean Absolute Error': 8.72111700741218, 'Max error': 275.81332931064196, 'Mean Squared Error': 471.64888865912025, 'Explained Variance Score': 0.5534538038478345, 'R^2 Score': 0.5090766748334936}\", \"ITA_random_patches_45 {'Root Mean Squared Error': 21.67320536216352, 'Mean Absolute Error': 8.68999629978127, 'Max error': 275.7571543610575, 'Mean Squared Error': 469.72783067051364, 'Explained Variance Score': 0.5505429935288002, 'R^2 Score': 0.5062489750650803}\", \"ITA_random_patches_50 {'Root Mean Squared Error': 21.684152733928144, 'Mean Absolute Error': 8.682085012281807, 'Max error': 277.1434642129153, 'Mean Squared Error': 470.20247978832333, 'Explained Variance Score': 0.5547217896408245, 'R^2 Score': 0.5105821927504778}\", \"ITA_random_patches_55 {'Root Mean Squared Error': 21.646240018710273, 'Mean Absolute Error': 8.696174708523925, 'Max error': 275.7465987710368, 'Mean Squared Error': 468.55970694761413, 'Explained Variance Score': 0.5520967203801929, 'R^2 Score': 0.5074768399003597}\", \"ITA_random_patches_60 {'Root Mean Squared Error': 22.1008049762677, 'Mean Absolute Error': 8.782850067136794, 'Max error': 276.3150104301598, 'Mean Squared Error': 488.4455805990191, 'Explained Variance Score': 0.5347327561509305, 'R^2 Score': 0.4915935681047249}\", \"ITA_random_patches_65 {'Root Mean Squared Error': 21.699473822574024, 'Mean Absolute Error': 8.673989806227818, 'Max error': 274.2720951793258, 'Mean Squared Error': 470.8671641765753, 'Explained Variance Score': 0.5498012364867886, 'R^2 Score': 0.5050322999690899}\", \"ITA_random_patches_70 {'Root Mean Squared Error': 21.58825164084428, 'Mean Absolute Error': 8.64452854117354, 'Max error': 273.48417980860614, 'Mean Squared Error': 466.0526089084158, 'Explained Variance Score': 0.5548197383065234, 'R^2 Score': 0.5101121579412334}\", \"ITA_random_patches_75 {'Root Mean Squared Error': 21.568990714348054, 'Mean Absolute Error': 8.63339646669806, 'Max error': 275.6130337926237, 'Mean Squared Error': 465.2213604356325, 'Explained Variance Score': 0.5552053763963632, 'R^2 Score': 0.5109670745830028}\", \"ITA_random_patches_80 {'Root Mean Squared Error': 21.4560640104457, 'Mean Absolute Error': 8.59024497699748, 'Max error': 274.26924368171564, 'Mean Squared Error': 460.3626828203433, 'Explained Variance Score': 0.559887183374931, 'R^2 Score': 0.5160930827541819}\", \"ITA_random_patches_85 {'Root Mean Squared Error': 21.60762206706757, 'Mean Absolute Error': 8.632258671591696, 'Max error': 273.8378523625896, 'Mean Squared Error': 466.8893313932254, 'Explained Variance Score': 0.5537035644768127, 'R^2 Score': 0.5092137313656183}\", \"ITA_random_patches_90 {'Root Mean Squared Error': 21.521973575786916, 'Mean Absolute Error': 8.614365354463974, 'Max error': 272.2413843180926, 'Mean Squared Error': 463.19534659687025, 'Explained Variance Score': 0.5575319329367472, 'R^2 Score': 0.5130967864981597}\", \"ITA_random_patches_95 {'Root Mean Squared Error': 21.549451280968412, 'Mean Absolute Error': 8.613884786934165, 'Max error': 274.7889267498498, 'Mean Squared Error': 464.37885051083117, 'Explained Variance Score': 0.556222170789655, 'R^2 Score': 0.5118527069469869}\", \"ITA_random_patches_100 {'Root Mean Squared Error': 21.57247243958504, 'Mean Absolute Error': 8.616649670167808, 'Max error': 274.8486619450225, 'Mean Squared Error': 465.3715671566562, 'Explained Variance Score': 0.5551523520395268, 'R^2 Score': 0.5108091797861458}\"]\n",
        "    printed_header = False\n",
        "    for i in results:\n",
        "        res = i.split(\"{\")\n",
        "        percent_run = res[0]\n",
        "        precent_run_result = \"{\"+res[1].replace(\"'\",\"\\\"\")\n",
        "        precent_run_result = json.loads(precent_run_result)\n",
        "        \n",
        "        if not printed_header:\n",
        "            print_str = f\"|{'Approach':^25}|\"\n",
        "            for key, val in precent_run_result.items():\n",
        "                print_str +=f\"{key:^25}|\"\n",
        "            print(print_str)\n",
        "            printed_header = True\n",
        "\n",
        "        print_str = f\"|{percent_run:25}|\"\n",
        "        for key, val in precent_run_result.items():\n",
        "            print_str += f\"{val:^25.3f}|\"\n",
        "        print(print_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyKb1xa5MW3a"
      },
      "source": [
        "\n",
        "### Random Entropy Limited patches\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeqfmpG3aVS3"
      },
      "source": [
        "def get_random_entropy_limited_patches_ita_list(image,percentage=PERCENTAGE_OF_RANDOM_ENTROPY_SELECTED_PATCHES, verbose=False):\n",
        "    \"\"\"\n",
        "    The method will return the \"selected\" patch indexs along with their computed ITA values\n",
        "    The selected patches will be based off of the entropy of a specific patch. A patch will\n",
        "    be picked up randomly which will then have the entropy check. If the entroy meets the\n",
        "    good criteria then it will keep that patch. The entropy does not meet the good critera then\n",
        "    that patch will be tossed and another random patch will be selected. Patches will be collected\n",
        "    until a total number of patches reaches the percentage coverage of a specific image. \n",
        "    \n",
        "    Possible tests\n",
        "    1. Adjust % coverage\n",
        "    2. Adjust disk radius\n",
        "    \"\"\"\n",
        "\n",
        "    #Trim the boarder\n",
        "    orig_image = Image.open(io.BytesIO(image))\n",
        "    # Crop image to remove the pixels from the boarder    \n",
        "    orig_image = trim_boarder_from_image(orig_image)\n",
        "\n",
        "    np_array_orig_image = np.array(orig_image)\n",
        "    #print(np_array_orig_image.shape)\n",
        "    orig_patches = patchify(np_array_orig_image, (PATCH_WIDTH,PATCH_HEIGHT,3), step=PATCH_WIDTH)\n",
        "\n",
        "    im_gray_scale = Image.open(io.BytesIO(image)).convert(\"L\")\n",
        "    im_gray_scale = trim_boarder_from_image(im_gray_scale)\n",
        "    np_array_im_gray_scale = np.array(im_gray_scale)\n",
        "    entropy_image = entropy(np_array_im_gray_scale, disk(5))\n",
        "    entropy_array = np.array(entropy_image)\n",
        "\n",
        "    entropy_patches = patchify(entropy_array, (PATCH_WIDTH,PATCH_HEIGHT), step=PATCH_WIDTH)\n",
        "\n",
        "\n",
        "\n",
        "    selected_ita_values = []\n",
        "  \n",
        "    row_count = len(orig_patches)\n",
        "    column_count = len(orig_patches[0])\n",
        "    \n",
        "\n",
        "    patch_count = row_count * column_count\n",
        "    target_count = math.ceil(percentage * patch_count)\n",
        "        \n",
        "    # Generate a random list of numbers with no duplicates for the whole set.\n",
        "    random_patch_indexes = rng.choice(patch_count, size=patch_count, replace=False)\n",
        "    \n",
        "    \n",
        "    # get reverse indexes. The index number comes from nRow * column_count + nCol. \n",
        "    # so for example if you have 10x10 image. image index 23 is row 2 col 4. The formula would be 2*10 + 4 = 24\n",
        "    # x = number % column_count\n",
        "    # y = int(number / column_count) \n",
        "    \n",
        "    coordinate_indices = []\n",
        "    good_coordinate_indices = []\n",
        "    for index in random_patch_indexes:\n",
        "        y = index % column_count\n",
        "        x = int(index /column_count)\n",
        "        coordinate_indices.append([x,y])\n",
        "\n",
        "\n",
        "    ita_values = []\n",
        "    for index in coordinate_indices:\n",
        "        x = index[1]\n",
        "        y = index[0]\n",
        "        patch = orig_patches[y][x]\n",
        "        entropy_patch = entropy_patches[y][x]\n",
        "        entropy_median = np.median(entropy_patch[0])\n",
        "        #print(f\"{x},{y} = {entropy_median}\")\n",
        "        if entropy_median < 4.5 and len(good_coordinate_indices) < target_count:\n",
        "            good_coordinate_indices.append([y,x])\n",
        "            ita_values.append(compute_ita_from_lab(patch[0]))\n",
        "        #check the entropy limits\n",
        "    #print(len(good_coordinate_indices), target_count, patch_count)\n",
        "    if verbose:\n",
        "        print(f\"row_count {row_count} column_count {column_count} \")\n",
        "        print(f\"patch_count {patch_count}, target_count {target_count}\")\n",
        "        print(f\"random_patch_indexes\\n{random_patch_indexes}\")\n",
        "        print(f\"coordinate_indices\\n{coordinate_indices}\")\n",
        "        print(f\"good_coordinate_indices\\n{good_coordinate_indices}\")\n",
        "    return ita_values, good_coordinate_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew7QnAej3adZ"
      },
      "source": [
        "def get_random_entropy_limited_patches_ita(row,percentage=PERCENTAGE_OF_RANDOM_ENTROPY_SELECTED_PATCHES):\n",
        "    \"\"\"\n",
        "    This function is intended to add the ITA represented value dataframe for an instance. \n",
        "    Its intended to be used with the df.apply() method\n",
        "    \"\"\"\n",
        "\n",
        "    image = row[\"image\"]\n",
        "    \n",
        "    ita_values, indices = get_random_entropy_limited_patches_ita_list(image, percentage)\n",
        "    row[f\"ITA_random_entropy_limited_patches_{int(percentage*100)}_all\"] = ita_values\n",
        "    row[f\"ITA_random_entropy_limited_patches_{int(percentage*100)}\"] = np.median(ita_values)\n",
        "    row[f\"ITA_random_entropy_limited_patches_{int(percentage*100)}_indices\"] = indices\n",
        "    return row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmfXiJee3eUu"
      },
      "source": [
        "#### Test 1 image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRQ1r9V_3dgO"
      },
      "source": [
        "index = 5\n",
        "ita, coords = get_random_entropy_limited_patches_ita_list(df.iloc[index][\"image\"],verbose=True)\n",
        "display_single_image_and_selected_patches(df.iloc[index][\"image\"],coords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7ycJxc04YYb"
      },
      "source": [
        "# display entropy pictures\n",
        "\n",
        "index = 5\n",
        "img = io.BytesIO(df.iloc[index][\"image\"])\n",
        "masked_image = Image.open(io.BytesIO(df.iloc[index][\"masked_image\"]))\n",
        "\n",
        "orig_image = Image.open(img)\n",
        "im_gray_scale = Image.open(img).convert(\"L\")\n",
        "np_array_im_gray_scale = np.array(im_gray_scale)\n",
        "\n",
        "# Create figure and axes\n",
        "fig, axes = plt.subplots(1,3)\n",
        "fig.set_size_inches(20,7)\n",
        "\n",
        "entropy_image = entropy(np_array_im_gray_scale, disk(20))\n",
        "# Display the image\n",
        "entropy_array = np.array(entropy_image)\n",
        "\n",
        "patches = patchify(entropy_array, (PATCH_WIDTH,PATCH_HEIGHT), step=PATCH_WIDTH)\n",
        "#print(patches)\n",
        "\n",
        "axes[0].imshow(orig_image)\n",
        "axes[1].imshow(masked_image)\n",
        "img1 = axes[2].imshow(entropy_image)\n",
        "\n",
        "fig.colorbar(img1, ax=axes[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q49Kbg8Y3sqb"
      },
      "source": [
        "### Evaluating 1 image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sPUEK1DzMxj"
      },
      "source": [
        "%%time\n",
        "orig_ita_values = get_ita_for_all_patches(df.iloc[0][\"image\"])[0]\n",
        "cropped_center_values = get_cropped_center_patches_ita_list(df.iloc[0][\"image\"])[0]\n",
        "structured_ita_values = get_structured_patches_ita_list(df.iloc[0][\"image\"])[0]\n",
        "random_ita_values = get_random_patches_ita_list(df.iloc[0][\"image\"])[0]\n",
        "random_entropy_limited_ita_values = get_random_entropy_limited_patches_ita_list(df.iloc[0][\"image\"])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgGCXUm71mJ2"
      },
      "source": [
        "print('displaying the number of patches per method')\n",
        "print(f\"|{'Method':20}|{'Count':^10}|{'Total %':^4}|\")\n",
        "print(f\"|{'All patches':20}|{len(orig_ita_values):^10}|{len(orig_ita_values)/len(orig_ita_values)*100:^3.3f}|\")\n",
        "print(f\"|{'Cropped Center':20}|{len(cropped_center_values):^10}|{len(cropped_center_values)/len(orig_ita_values)*100:^3.3f}|\")\n",
        "print(f\"|{'Structured Patches':20}|{len(structured_ita_values):^10}|{len(structured_ita_values)/len(orig_ita_values)*100:^3.3f}|\")\n",
        "print(f\"|{'Random Patches':20}|{len(random_ita_values):^10}|{len(random_ita_values)/len(orig_ita_values)*100:^3.3f}|\")\n",
        "print(f\"|{'Random Entropy Limted':20}|{len(random_entropy_limited_ita_values):^10}|{len(random_entropy_limited_ita_values)/len(orig_ita_values)*100:^3.3f}|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmTuaqzn2IwG"
      },
      "source": [
        "f, axes = plt.subplots(1, 5)\n",
        "f.set_size_inches(20,7)\n",
        "\n",
        "\n",
        "ax = sns.distplot(orig_ita_values,ax=axes[0]).set_title(\"ITA patches of Original image\")\n",
        "#TODO Add masked \n",
        "#ax = sns.distplot(orig_ita_values,ax=axes[0]).set_title(\"ITA patches of Original image\")\n",
        "ax = sns.distplot(cropped_center_values,ax=axes[1]).set_title(\"ITA with cropped center\")\n",
        "ax = sns.distplot(structured_ita_values,ax=axes[2]).set_title(\"Structured ITA\")\n",
        "ax = sns.distplot(random_ita_values,ax=axes[3]).set_title(\"Random ITA\")\n",
        "ax = sns.distplot(random_entropy_limited_ita_values,ax=axes[4]).set_title(\"Random Entropy Limited ITA\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uat412jICLw_"
      },
      "source": [
        "## Calculate ITA on all images using following methods\n",
        "\n",
        "1. Cropped center\n",
        "2. Structured approach\n",
        "3. Random patches\n",
        "4. Smart Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mfjVa47CK6t"
      },
      "source": [
        "%%time\n",
        "df = df.apply(get_cropped_center_ita, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0LBlkwv4yrC"
      },
      "source": [
        "%%time\n",
        "df = df.apply(get_structured_patches_ita, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AZ4YlwI41N4"
      },
      "source": [
        "%%time\n",
        "df = df.apply(get_random_patches_ita, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDrKRHba43rv"
      },
      "source": [
        "%%time\n",
        "df = df.apply(get_random_entropy_limited_patches_ita, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q5F56aYhQCI"
      },
      "source": [
        "## Add the ITA category to the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqybVnO2Pkvd"
      },
      "source": [
        "def add_ita_category(ita):\n",
        "    if ita <= 10:\n",
        "        return \"dark\"\n",
        "    elif 10 < ita <= 19:\n",
        "        return \"tan1\"\n",
        "    elif 19 < ita <= 28:\n",
        "        return \"tan2\"\n",
        "    elif 28 < ita <= 34.5:\n",
        "        return \"int1\"\n",
        "    elif 34.5 < ita <= 41:\n",
        "        return \"int2\"\n",
        "    elif 41 < ita <= 48:\n",
        "        return \"lt1\"\n",
        "    elif 48 < ita <= 55:\n",
        "        return \"lt2\"\n",
        "    elif 55 < ita:\n",
        "        return \"very_lt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D3zxNVbO4a9"
      },
      "source": [
        "%%time\n",
        "df[\"ITA_orig_category\"] = df[\"ITA_orig\"].apply(add_ita_category)\n",
        "df[\"ITA_masked_category\"] = df[\"ITA_masked\"].apply(add_ita_category)\n",
        "df[\"ITA_center_cropped_category\"] = df[\"ITA_center_cropped\"].apply(add_ita_category)\n",
        "df[\"ITA_structured_patches_category\"] = df[\"ITA_structured_patches\"].apply(add_ita_category)\n",
        "df[f\"ITA_random_patches_{PERCENTAGE_OF_RANDOM_PATCHES_NAME}_category\"] = df[f\"ITA_random_patches_{PERCENTAGE_OF_RANDOM_PATCHES_NAME}\"].apply(add_ita_category)\n",
        "df[f\"ITA_random_entropy_limited_patches_{PERCENTAGE_OF_RANDOM_ENTROPY_SELECTED_PATCHES_NAME}_category\"] = df[f\"ITA_random_entropy_limited_patches_{PERCENTAGE_OF_RANDOM_ENTROPY_SELECTED_PATCHES_NAME}\"].apply(add_ita_category)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-k-RCLcXr0R"
      },
      "source": [
        "# Display images with ITA values along with Lab values\n",
        "\n",
        "This initial display of images was to get a rough feel to see how the ITA values aligned up with a small sample of images. The ITA values seem to do a decent job a representing the skin tones but there ware a few that seem off such as row 0 col 3. This image is classified as a dark skin tone with an ITA value of 8.56. I think the subject of the image is swinging the ITA value lower than if it was segmented out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXDpY_o5uOMe"
      },
      "source": [
        "%%time\n",
        "ITA_Categories_list = [\"dark\", \"tan1\", \"tan2\", \"int1\", \"int2\", \"lt1\", \"lt2\", \"very_lt\"]\n",
        "ITA_Categories_list.reverse()\n",
        "        \n",
        "plt.figure(figsize=(15, 70))\n",
        "index = 0\n",
        "display_image_count = 1\n",
        "col_count = 6\n",
        "for cat in ITA_Categories_list:\n",
        "    cat_df = df[df[\"ITA_masked_category\"] == cat]\n",
        "    #print(cat_df.head())\n",
        "    for ele in cat_df.head(display_image_count).iterrows():\n",
        "        #print(ele[1])\n",
        "\n",
        "        removal_size = get_border_removal_size(Image.open(io.BytesIO(ele[1][\"image\"])))\n",
        "        \n",
        "        # Original\n",
        "        ax = plt.subplot(8*col_count, col_count, index + 1)\n",
        "        img = io.BytesIO(ele[1][\"image\"])\n",
        "        plt.imshow(Image.open(img),aspect=.7)     \n",
        "           \n",
        "        title = f\"{'Orig':15}{ele[1]['ITA_orig_category']:^7}{ele[1]['ITA_orig']:^3.2f}\"\n",
        "        plt.title(title)\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplots_adjust(hspace = .5)        \n",
        "        index += 1\n",
        "\n",
        "        # Masked\n",
        "        ax = plt.subplot(8*col_count, col_count, index + 1)\n",
        "        img = io.BytesIO(ele[1][\"masked_image\"])\n",
        "        plt.imshow(Image.open(img),aspect=.7)        \n",
        "        title = f\"{'masked':15}{ele[1]['ITA_masked_category']:^7}  {ele[1]['ITA_masked']:^5.2f}\"\n",
        "        plt.title(title)\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplots_adjust(hspace = .5)\n",
        "        index += 1\n",
        "\n",
        "        # Center cropped\n",
        "        ax = plt.subplot(8*col_count, col_count, index + 1)\n",
        "        img = io.BytesIO(ele[1][\"image\"])\n",
        "        plt.imshow(Image.open(img),aspect=.7)        \n",
        "        title = f\"{'Center Crop':15}{ele[1]['ITA_center_cropped_category']:^7}  {ele[1]['ITA_center_cropped']:^5.2f}\"\n",
        "        plt.title(title)\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplots_adjust(hspace = .5)            \n",
        "        coords = ele[1][\"ITA_center_cropped_indices\"]\n",
        "        for coord in coords:\n",
        "            # Create a Rectangle patch    \n",
        "            x = coord[0] * PATCH_WIDTH + removal_size\n",
        "            y = int(coord[1] * PATCH_WIDTH) + removal_size    \n",
        "            rect = mplpatches.Rectangle((y, x), PATCH_HEIGHT, PATCH_WIDTH, linewidth=1, edgecolor='b', facecolor='none')\n",
        "\n",
        "            # Add the patch to the Axes\n",
        "            ax.add_patch(rect)\n",
        "        index += 1\n",
        "\n",
        "        # Structured\n",
        "        ax = plt.subplot(8*col_count, col_count, index + 1)\n",
        "        img = io.BytesIO(ele[1][\"image\"])\n",
        "        plt.imshow(Image.open(img),aspect=.7)        \n",
        "        title = f\"{'Structured':15}{ele[1]['ITA_structured_patches_category']:^7}  {ele[1]['ITA_structured_patches']:^5.2f}\"\n",
        "        plt.title(title)\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplots_adjust(hspace = .5)\n",
        "        coords = ele[1][\"ITA_structured_patches_indices\"]\n",
        "        for coord in coords:\n",
        "            # Create a Rectangle patch    \n",
        "            x = coord[0] * PATCH_WIDTH + removal_size\n",
        "            y = int(coord[1] * PATCH_WIDTH) + removal_size    \n",
        "            rect = mplpatches.Rectangle((y, x), PATCH_HEIGHT, PATCH_WIDTH, linewidth=1, edgecolor='b', facecolor='none')\n",
        "\n",
        "            # Add the patch to the Axes\n",
        "            ax.add_patch(rect)\n",
        "        index += 1\n",
        "\n",
        "        # Random\n",
        "        ax = plt.subplot(8*col_count, col_count, index + 1)\n",
        "        img = io.BytesIO(ele[1][\"image\"])\n",
        "        plt.imshow(Image.open(img),aspect=.7)        \n",
        "        title = f\"{'Random':15}{ele[1][f'ITA_random_patches_{PERCENTAGE_OF_RANDOM_PATCHES_NAME}_category']:^7}  {ele[1][f'ITA_random_patches_{PERCENTAGE_OF_RANDOM_PATCHES_NAME}']:^5.2f}\"\n",
        "        plt.title(title)\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplots_adjust(hspace = .5)\n",
        "        coords = ele[1][f\"ITA_random_patches_{PERCENTAGE_OF_RANDOM_PATCHES_NAME}_indices\"]\n",
        "        for coord in coords:\n",
        "            # Create a Rectangle patch    \n",
        "            x = coord[0] * PATCH_WIDTH + removal_size\n",
        "            y = int(coord[1] * PATCH_WIDTH) + removal_size    \n",
        "            rect = mplpatches.Rectangle((y, x), PATCH_HEIGHT, PATCH_WIDTH, linewidth=1, edgecolor='b', facecolor='none')\n",
        "\n",
        "            # Add the patch to the Axes\n",
        "            ax.add_patch(rect)\n",
        "        index += 1\n",
        "        #create columns for Random entropy column\n",
        "        ax = plt.subplot(8*col_count, col_count, index + 1)\n",
        "        img = io.BytesIO(ele[1][\"image\"])\n",
        "        plt.imshow(Image.open(img),aspect=.7)        \n",
        "        title = f\"{'Random':15}{ele[1][f'ITA_random_entropy_limited_patches_{PERCENTAGE_OF_RANDOM_ENTROPY_SELECTED_PATCHES_NAME}_category']:^7}  {ele[1][f'ITA_random_entropy_limited_patches_{PERCENTAGE_OF_RANDOM_ENTROPY_SELECTED_PATCHES_NAME}']:^5.2f}\"\n",
        "        plt.title(title)\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplots_adjust(hspace = .5)\n",
        "        coords = ele[1][f\"ITA_random_entropy_limited_patches_{PERCENTAGE_OF_RANDOM_ENTROPY_SELECTED_PATCHES_NAME}_indices\"]\n",
        "        for coord in coords:\n",
        "            # Create a Rectangle patch    \n",
        "            x = coord[0] * PATCH_WIDTH + removal_size\n",
        "            y = int(coord[1] * PATCH_WIDTH) + removal_size    \n",
        "            rect = mplpatches.Rectangle((y, x), PATCH_HEIGHT, PATCH_WIDTH, linewidth=1, edgecolor='b', facecolor='none')\n",
        "\n",
        "            # Add the patch to the Axes\n",
        "            ax.add_patch(rect)\n",
        "        index += 1\n",
        "\n",
        "\n",
        "        #TODO - create columns for smart random\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52tpEc2LSp4F"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHIt3Hinnrn7"
      },
      "source": [
        "# Evaluate ITA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH3rY_xL2OOz"
      },
      "source": [
        "catagories_to_test = [\"ITA_orig\", \"ITA_center_cropped\", \"ITA_structured_patches\", \"ITA_random_patches\"]\n",
        "plt.figure(figsize=(5, 10))\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
        "\n",
        "ax = sns.violinplot(data=df, y=\"ITA_masked\", x=\"ITA_masked_category\", order=ITA_Categories_list,ax=axes[0,0])\n",
        "ax.set_ylim(-50,100)\n",
        "\n",
        "ax = sns.violinplot(data=df, y=\"ITA_orig\", x=\"ITA_orig_category\", order=ITA_Categories_list,ax=axes[0,1])\n",
        "ax.set_ylim(-50,100)\n",
        "\n",
        "ax = sns.violinplot(data=df, y=\"ITA_center_cropped\", x=\"ITA_center_cropped_category\", order=ITA_Categories_list,ax=axes[1,0])\n",
        "ax.set_ylim(-50,100)\n",
        "\n",
        "ax = sns.violinplot(data=df, y=\"ITA_structured_patches\", x=\"ITA_structured_patches_category\", order=ITA_Categories_list,ax=axes[1,1])\n",
        "ax.set_ylim(-50,100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VlrDcQ7zpgr"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.figure(figsize=(5, 10))\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
        "\n",
        "ax = sns.boxplot(data=df, y=\"ITA_masked\", x=\"ITA_masked_category\", order=ITA_Categories_list,ax=axes[0,0])\n",
        "ax.set_ylim(-120,100)\n",
        "\n",
        "ax = sns.boxplot(data=df, y=\"ITA_orig\", x=\"ITA_orig_category\", order=ITA_Categories_list,ax=axes[0,1])\n",
        "ax.set_ylim(-120,100)\n",
        "\n",
        "ax = sns.boxplot(data=df, y=\"ITA_center_cropped\", x=\"ITA_center_cropped_category\", order=ITA_Categories_list,ax=axes[1,0])\n",
        "ax.set_ylim(-120,100)\n",
        "\n",
        "ax = sns.boxplot(data=df, y=\"ITA_structured_patches\", x=\"ITA_structured_patches_category\", order=ITA_Categories_list,ax=axes[1,1])\n",
        "ax.set_ylim(-120,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI3_-JPyyWkK"
      },
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
        "\n",
        "ax = sns.swarmplot(data=df, y=\"ITA_masked\", x=\"ITA_masked_category\", order=ITA_Categories_list,ax=axes[0,0])\n",
        "ax.set_ylim(-120,100)\n",
        "\n",
        "ax = sns.swarmplot(data=df, y=\"ITA_orig\", x=\"ITA_orig_category\", order=ITA_Categories_list,ax=axes[0,1])\n",
        "ax.set_ylim(-120,100)\n",
        "\n",
        "ax = sns.swarmplot(data=df, y=\"ITA_center_cropped\", x=\"ITA_center_cropped_category\", order=ITA_Categories_list,ax=axes[1,0])\n",
        "ax.set_ylim(-120,100)\n",
        "\n",
        "ax = sns.swarmplot(data=df, y=\"ITA_structured_patches\", x=\"ITA_structured_patches_category\", order=ITA_Categories_list,ax=axes[1,1])\n",
        "ax.set_ylim(-120,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heM1TCgHomGH"
      },
      "source": [
        "f, axes = plt.subplots(1, 6)\n",
        "f.set_size_inches(28,7)\n",
        "\n",
        "ax = sns.histplot(df.ITA_masked_category,kde=True,ax=axes[0]).set_title(\"Categories with masking(GT)\")\n",
        "ax = sns.histplot(df.ITA_orig_category,kde=True,ax=axes[1]).set_title(\"Categories Original\")\n",
        "ax = sns.histplot(df.ITA_center_cropped_category,kde=True,ax=axes[2]).set_title(\"Categories with centered cropped\")\n",
        "ax = sns.histplot(df.ITA_structured_patches_category,kde=True,ax=axes[3]).set_title(\"Categories Structured\")\n",
        "ax = sns.histplot(df.ITA_random_patches_20_category,kde=True,ax=axes[4]).set_title(\"Categories random\")\n",
        "ax = sns.histplot(df.ITA_random_entropy_limited_patches_20_category,kde=True,ax=axes[5]).set_title(\"Categories random entropy limited\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m5QgmtRowLP"
      },
      "source": [
        "## Performance metrics\n",
        "\n",
        "Table 3: Evaluation metrics of skin tone predictions compared to manually annotated ground-truth. Metrics are  MAE: mean absolute error;\n",
        "MSE: mean squared error; and rMSE: root mean squared\n",
        "error.\n",
        "\n",
        "Here is a list of other metrics we can look at https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i2hYTtTkoak"
      },
      "source": [
        "def compute_metrics(df, column, filter_percentage=None):\n",
        "    results = {}\n",
        "    df_temp = df\n",
        "    if filter_percentage is not None:\n",
        "        df_temp = df_temp[df_temp[\"mask_percentage\"] == filter_percentage]\n",
        "\n",
        "    \n",
        "    # drop any NAN rows\n",
        "    df_temp = df_temp[df_temp[column].notna()]\n",
        "    df_temp = df_temp[df_temp[\"ITA_masked\"].notna()]    \n",
        "\n",
        "\n",
        "    results[\"Root Mean Squared Error\"] = mean_squared_error(df_temp.ITA_masked, df_temp[column], squared=False)\n",
        "    results[\"Mean Absolute Error\"] = mean_absolute_error(df_temp.ITA_masked, df_temp[column])\n",
        "    results[\"Max error\"] = max_error(df_temp.ITA_masked, df_temp[column])\n",
        "    #results[\"Mean Squared Error\"] = mean_squared_error(df_masked_updated, df_column_updated)    \n",
        "    #results[\"Explained Variance Score\"] = explained_variance_score(df_masked_updated, df_column_updated)\n",
        "    #results[\"R^2 Score\"] = r2_score(df_masked_updated, df_column_updated)\n",
        "    \n",
        "    # Cant do the following because there are negative values in ITA and these metrics dont support negative values\n",
        "    # \n",
        "    #results[\"Mean Squared Log Error\"] = mean_squared_log_error(df_masked_updated, df_column_updated)\n",
        "    #results[\"Mean Poisson Deviance\"] = mean_poisson_deviance(df_masked_updated, df_column_updated)\n",
        "    #results[\"Mean Gamma Deviance\"] = mean_gamma_deviance(df_masked_updated, df_column_updated)\n",
        "    #results[\"Mean Tweedie Deviance\"] = mean_tweedie_deviance(df_masked_updated, df_column_updated)\n",
        "\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKjNHna_podd"
      },
      "source": [
        "# evaluating using mean squared error\n",
        "# as part of the ITA calculation some rows could not compute the ITA value. \n",
        "# We will do some preprocess to drop those rows\n",
        "catagories_to_test = [\"ITA_orig\", \"ITA_center_cropped\", \"ITA_structured_patches\",\n",
        "                      f\"ITA_random_patches_{PERCENTAGE_OF_RANDOM_PATCHES_NAME}\",\n",
        "                      f\"ITA_random_entropy_limited_patches_{PERCENTAGE_OF_RANDOM_ENTROPY_SELECTED_PATCHES_NAME}\"]\n",
        "\n",
        "printed_header = False\n",
        "for cat in catagories_to_test:\n",
        "    results = compute_metrics(df,cat)\n",
        "    if not printed_header:\n",
        "        print_str = f\"|{'Approach':^25}|\"\n",
        "        for key, val in results.items():\n",
        "            print_str +=f\"{key:^25}|\"\n",
        "        print(print_str)\n",
        "        printed_header = True\n",
        "\n",
        "    print_str = f\"|{cat:25}|\"\n",
        "    for key, val in results.items():\n",
        "        print_str += f\"{val:^25.3f}|\"\n",
        "    print(print_str)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT2SO224o1Q_"
      },
      "source": [
        "## Confusion matrix of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng9klXS9n7IR"
      },
      "source": [
        "plt.figure(figsize=(14, 14))\n",
        "cols = 2\n",
        "rows = 3\n",
        "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(15,10))\n",
        "\n",
        "plot_titles = [\"ITA Categories for Original\", \"ITA Categories for Center Cropped\", \"ITA Categories for Structured\", \"ITA Categories for Random Patches\", \"ITA Random Entropy Limited\"]\n",
        "\n",
        "for index, cat in enumerate(catagories_to_test):\n",
        "    \n",
        "    category = f\"{cat}_category\"    \n",
        "    df_temp = df[df[category].notna()]\n",
        "    df_temp = df_temp[df_temp[\"ITA_masked_category\"].notna()]\n",
        "    \n",
        "\n",
        "    cm = confusion_matrix(df_temp.ITA_masked_category,df_temp[category],normalize=\"true\")\n",
        "    df_cm = pd.DataFrame(cm,columns=np.unique(df_temp.ITA_masked_category.to_numpy()),index=np.unique(df_temp.ITA_masked_category.to_numpy()))\n",
        "    row = index % cols\n",
        "    col = int(index/cols)\n",
        "    ax = sns.heatmap(df_cm, annot=True,cmap=\"Blues\",ax=axes[col,row])\n",
        "    ax.set_title(plot_titles[index])\n",
        "    ax.set_ylabel('True label')\n",
        "    ax.set_xlabel('Predicted label')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5oA1Sa2b0rj"
      },
      "source": [
        "## Compare the lesion size vs error\n",
        "This section will go over comparing the lesion size which will be made up from taking the count of the masked pixels and comparing that to the total count of pixels to come up with a percentrage. This percentage will be used to comapre the error to see how the lesion size might affect the ITA computations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oITbKNNpc8dX"
      },
      "source": [
        "# compute the error\n",
        "catagories_to_test = [\"ITA_orig\", \"ITA_center_cropped\", \"ITA_structured_patches\",\n",
        "                      f\"ITA_random_patches_{PERCENTAGE_OF_RANDOM_PATCHES_NAME}\",\n",
        "                      f\"ITA_random_entropy_limited_patches_{PERCENTAGE_OF_RANDOM_ENTROPY_SELECTED_PATCHES_NAME}\"]\n",
        "\n",
        "printed_header = False\n",
        "# Get list of percentages\n",
        "percentage = df.mask_percentage.unique()\n",
        "percentage.sort()\n",
        "print(percentage)\n",
        "results_list = []\n",
        "for p in percentage:\n",
        "    print(f\"--{p}--\")\n",
        "    for cat in catagories_to_test:\n",
        "        try:\n",
        "            results = compute_metrics(df,cat,p)\n",
        "            if not printed_header:\n",
        "                print_str = f\"|{'Approach':^25}|\"\n",
        "                for key, val in results.items():\n",
        "                    print_str +=f\"{key:^25}|\"\n",
        "                print(print_str)\n",
        "                printed_header = True\n",
        "            \n",
        "            current_result = [cat,p]\n",
        "            print_str = f\"|{cat:25}|\"\n",
        "            for key, val in results.items():\n",
        "                print_str += f\"{val:^25.3f}|\"\n",
        "                current_result.append(val)\n",
        "            print(print_str)\n",
        "            results_list.append(current_result)\n",
        "        except:\n",
        "            print(\"Compute_metrics probably had a issue with an nan\")\n",
        "    \n",
        "\n",
        "df_metrics_on_percentage = pd.DataFrame(data=results_list, columns=[\"approach\",\"percentage\", \"root_mean_squared_error\", \"mean_absolute_error\", \"max_error\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUzLF4Ije5QP"
      },
      "source": [
        "df_metrics_on_percentage.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcAeJDiZnmMP"
      },
      "source": [
        "plt.figure(figsize=(20, 14))\n",
        "sns.barplot(data=df_metrics_on_percentage,hue=\"approach\", x=\"percentage\", y=\"root_mean_squared_error\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLcHVLwTn80T"
      },
      "source": [
        "plt.figure(figsize=(20, 14))\n",
        "sns.barplot(data=df_metrics_on_percentage,hue=\"approach\", x=\"percentage\", y=\"mean_absolute_error\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXJr1v7Xxdxj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}